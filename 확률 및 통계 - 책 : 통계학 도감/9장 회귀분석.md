# 9장 회귀분석
* 회귀분석
    * 원인(독립변수, 설명변수, 예측변수)과 결과(종속변수, 반응변수, 피설명변수, 목적변수) 사이에 **인과관계**를 밝히는 것
* 회귀선(회귀식)
    * 독립변수와 종속변수에 있는 관계를 직선 또는 곡선의 식으로 나타낸 것
    * 원인이 결과에 주는 영향의 정도를 수치화 할 수 있고, 예측 등에 응용할 수 있음
    * 데이터에 의해 추정된 함수(모델)
    * 회귀직선, 회귀평면, 회귀곡선이라고도 함
* 단회귀식(<- 단순회귀분석)
    * 독립변수가 하나인 회귀식
    * 이론 모델  : y(종속변수) = α(절편) + β(기울기)x(독립변수) + u(오차항)
        * 오차항
            * 독립변수 이외에 종속변수에 영향을 줌
            * 정규분포를 따르는 확률변수
    * 추정된 모델
        * y햇 = α햇 + β햇x
        * 추정된 파라미터는 불편추정량임
* 잔차(u햇)
    * 관측값과 예측값의 차이
    * 오차항의 추정량
    * u햇 = y - y햇
* 회귀식 추정방법
    * (보통) 최소제곱법(OLS : Ordinary Least Squares)
        * 회귀식의 파라미터를 추정하는 방법 중 하나임
        * 잔차제곱합을 최소화하는 모델 파라미터를 선택
            * 잔차제곱합 : 잔차들의 제곱합
        * 오차의 등분산성과 독립성이 요구됨
            * 이러한 가정을 바탕으로 최소제곱법을 통한 추정량이 최량(best) 선형 비편향 추정량이 됨
            * [참고사이트](https://jangpiano-science.tistory.com/119)
    * [최대우도법](https://hsm-edu.tistory.com/1226)
* 결정계수(R^2)
    * 회귀식의 평가지표
    * 회귀식의 성능을 알 수 있음
    * 0 ~ 1, 1에 가까울수록 좋음
        * 음수가 나올 수도 있는데, 성능이 매우 안좋은 것을 의미함
    * 관측값(y)와 예측값(y햇)의 상관계수의 제곱과 같아짐
    * 예측값으로 설명된 변동 / 전변동 = SSR / SST
        * SST = Σ(yi - y¯)^2
            * 전변동
            * 편차제곱합
        * SSR = Σ(y햇i - y¯)^2
            * 예측값으로 설명된 변동
        * SSE = Σ(yi - y햇i)^2
            * 예측값으로 설명되지 않은 변동
            * 잔차제곱합
* 회귀계수 t-검정(OLS)
    * 오차의 정규성이 요구됨
    * 회귀계수는 표본으로부터 추정하는 확률변수로 해석할 수 있음
    * 독립변수가 종속변수에 영향(원인)을 주는지 확인하기 위해 회귀계수를 검정함
        * 귀무가설 : βi = 0
        * 대립가설 : βi != 0
* 월드 검정(wald-test)
    * 최대우도법으로 추정한 경우에 이용되며, 귀무가설은 βi = 0
* 회귀계수 F-검정
    * 중회귀식 그 자체가 통계적으로 의미가 있는지 알고 싶을 때 진행함
        * 중회귀식 : y = β0 + β1x1 + β2x2 + ... + βnxn
    * 절편을 제외한 모든 회귀계수가 0이라는 귀무가설하에서 F 검정을 실시함
* 잔차분석
    * 잔차(u햇)와 예측값(y햇)의 산포도(잔차 플롯)를 활용하면 편리함(<-시각화)
    * 이상치 또는 회귀식의 부적절함(높은 차수의 회귀식을 사용해야함)을 발견할 수 있음
    * 오차의 등분산성 가정으로 인해서, 잔차 또한 등분산성이 만족해야 바람직함
        * 잔차의 등분산성 : 잔차 산점도가 -3과 3 사이에 고르게(잔차 산점도의 회귀선 기울기 = 0) 분포되어 있음
        * 잔차의 이분산성이 발생할 경우, 종속변수를 로그 스케일로 변환 또는 가중 최소 제곱법을 사용해야함
* 더미변수(dummy variable)
    * 더미변수는 1과 0에 값을 취하는 변수
    * one-hot encoding 기반으로 생성
    * 일시적 더미
        * 이상치가 있는 경우, 회귀식에 대한 영향을 줄이는 방법
        * 이상치에 1, 기타는 0을 적용한 일시적 더미변수를 이용함
            * 학습 : 회귀식 + 일시적 더미
            * 예측 : 회귀식
    * 절편 더미
        * 질적 데이터에 이용하는 더미변수
        * 회귀선의 절편을 변화시키는 역할을 함
            * 절편 더미의 회귀계수가 통계적으로 유의미하면 회귀선의 절편이 질적 데이터에 존재하는 집단마다 다름
        * 상수항 더미라고도 함
    * 기울기 더미
        * 기울기(선형 회귀식에 경우)에도 질적 데이터 간에 차이를 나타낼 때 사용함
        * 더미변수와 독립변수를 곱한 변수를 활용함
            * 더미변수와 독립변수를 곱한 변수의 회귀계수가 통계적으로 유의미하면 회귀선의 기울기가 집단마다 다름
* 중회귀분석
    * 독립변수가 여러 개 있을 경우에 이용함
    * 중회귀식의 회귀계수를 편회귀계수라고도 부름
        * 해당 독립변수가 종속변수에 주는 영향을 나타냄
    * 표준편회귀계수
        * 종속변수와 독립변수를 표준화해서 얻은 회귀계수를 표준회귀계수라고함
        * **(caution) 표본평균과 표본표준편차를 통해 진행함**
        * 스케일이 다른 독립변수 간에 회귀계수의 크기를 비교할 경우에 사용함
        * 표준화된 종속변수의 평균값이 0이므로 절편 또한 0임
    * 자유도가 조정된 결정계수
        * 기존의 결정계수는 독립변수를 늘리면 값이 상승하는 결점이 있음
            * 모델이 학습 데이터에 overfitting 되는 것과 연관 있는 것 같음
        * 이러한 문제점이 발생하지 않도록 고안한 지표가 자유도 조정 결정계수임
        * 독립변수의 수가 다른 회귀식의 적합도를 비교할 때 사용함
    * 다중공선성
         * 독립변수들 간에 상관관계가 높을 때, 다중공선성이 있다고 함
         * 다중공선성을 발견하는 VIF와 허용도라는 지표를 이용함
            * VIF(분산확대요인, Variance inflation factor)과 허용도는 역수 관계임
         * 회귀계수가 기대한 부호가 되지 않는 문제가 발생함
            * VIF 또는 허용도의 일정기준과 비교하여 조건 불충분일 때, 한쪽의 변수를 회귀식에 사용하지 않아야 함
* 변수선택법(variable selection)
    * 어느 독립변수를 회귀식에 포함시킬지를 정하는 방법
    * 설명력이 낮은 독립변수를 분석에서 제외시키는 것
    * 특정 독립변수를 제외시킴으로써 다중공선성의 문제를 피할 수 있음
    * 회귀식에서 변수를 삭제하는 기준, 포함시키는 기준에는 t-검정의 p값과 같은 통계적인 방법을 활용함
        * 종류
            * 감소법
            * 증가법
            * 감증법
            * 증감법
* 헥갈리는 용어
    * OLS vs MSE
        * 둘다 제곱 개념이 헥갈려서 정리함
        * OLS
            * 회귀식 파라미터를 추정하는 방법
        * MSE
            * 회귀식에 평가지표
    * 추정량 vs 추정값 vs 예측값
        * 추정량
            * 모수를 추정하기 위한 규칙이나 방법
            * 데이터에서 모수를 추정하기 위한 식                                                              
        * 추정값
            * 추정량에 데이터를 대입해서 얻어진 값
            * OLS나 최대우도법에 의해 추정된 parameter, coefficient
        * 예측값
            * 특정 독립변수를 대입해서 얻어진 종속변수의 값
* 프로빗 분석
    * 종속변수가 0과 1로만 구성 되어 있을 때 이용하는 분석방법(= binary classification)
    * 관측 데이터의 배후에 잠재적인 변수를 상정하는 것이 이 기법의 특징
        * 잠재변수
            * 실제로는 관측할 수 없는 모델 속에 가정하는 변수
            * 잠재변수 Y = α + β1x1 + β2x2 + ... + βnxn
    * 잠재변수를 선택확률(예측값)로 변환하기 위해서 누적정규분포를 활용함
    * 회귀계수(βi)와 절편(α)의 추정은 최대우도법을 이용함
    * 한계효과
        * 회귀계수는 독립변수가 잠재변수 Y에 영향을 주는 정도를 나타냄
        * 독립변수가 선택확률에 영향을 주는 정도(어느 정도 변화하는지)를 한계효과라고 함
        * 회귀계수와 한계효과의 부호는 같음
        * 편미분을 통해 구해짐
    * 적합도(Performance measure)
        * 유사결정계수
        * 정확도(적중도)
    * 유사한 분석으로 로짓 분석이 있음
        * 로지스틱 분포(= sigmoid 함수)를 활용하는 logistic regression을 의미함
* 생존곡선 및 생존분석 생략
* caution
    * 상관관계 vs 인과관계
        * 상관관계는 관련성 정도를 알 수 있음
        * 회귀분석은 인과관계를 추정하고, 예측을 할 수 있음
    * 외관상의 관계를 인과관계로 인식해버리는 오류
        * 과거의 연구자료를 충분히 읽어 보고 상식을 고려해 외관상의 관계를 바라 볼 수 있어야 됨
        * 인과관계 : ex> 흡연을 하면 폐암에 걸림
        * 상관관계 : ex> 커피를 자주 마심 - 흡연을 함
        * 외관상의 관계 : ex> 커피를 자주마시면 폐암에 걸림